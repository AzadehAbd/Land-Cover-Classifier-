{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c92b8515-9b71-40ad-af19-4a3d1e2efa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4ad426c-02b0-4889-be6c-aac127d62d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('F:/Landcover Classification_North Greece/CSV/sample345.csv')\n",
    "\n",
    "# Data Preprocessing\n",
    "# Separate the dependent and independent variables\n",
    "X = data.drop(columns=['Veg-Code','Centroid_x','Centroid_y','ID'])  # Independent variables\n",
    "y = data['Veg-Code']  # Dependent variable\n",
    "\n",
    "# Encode categorical variables like Aspect and Slope if necessary\n",
    "X['Aspect'] = LabelEncoder().fit_transform(X['Aspect'])\n",
    "X['Slope'] = LabelEncoder().fit_transform(X['Slope'])\n",
    "\n",
    "# Adjust target variable if necessary (0-based index for class labels)\n",
    "y = y - 1  # Assuming 'Veg-Code' starts from 1 to N classes\n",
    "\n",
    "# Standardize continuous features (optional but recommended for certain models)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Stratified train-test split: 70% train, 30% test with stratified sampling on 'Veg-Code'\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac5b5f36-897d-43d2-9f34-aa636de730ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the classifiers with added algorithms\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=500, solver='newton-cg', penalty='l2', class_weight='balanced'),\n",
    "    'Random Forest': RandomForestClassifier(class_weight='balanced'),\n",
    "    'Extra Trees': ExtraTreesClassifier(class_weight='balanced'),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(class_weight='balanced'),\n",
    "    'SVM (Linear Kernel)': SVC(kernel='linear', max_iter=600000, class_weight='balanced', C=0.1),\n",
    "    'SVM (RBF Kernel)': SVC(kernel='rbf', max_iter=600000, class_weight='balanced', C=0.1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'HistGradient Boosting': HistGradientBoostingClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(algorithm='SAMME'),\n",
    "    'XGBoost': xgb.XGBClassifier(eval_metric='mlogloss'),\n",
    "    'LightGBM': lgb.LGBMClassifier(force_col_wise=True, class_weight='balanced'),\n",
    "    'CatBoost': cb.CatBoostClassifier(verbose=0)\n",
    "}\n",
    "\n",
    "\n",
    "# Dictionary to store the results\n",
    "results_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f20c0bb-acd8-43a1-9369-ea02659262e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Test Accuracy: 0.703\n",
      "Training Accuracy: 0.732\n",
      "Logistic Regression completed with Accuracy: 0.7026\n",
      "Training Random Forest...\n",
      "Test Accuracy: 0.707\n",
      "Training Accuracy: 1.000\n",
      "Random Forest completed with Accuracy: 0.7070\n",
      "Training Extra Trees...\n",
      "Test Accuracy: 0.710\n",
      "Training Accuracy: 1.000\n",
      "Extra Trees completed with Accuracy: 0.7102\n",
      "Training KNN...\n",
      "Test Accuracy: 0.641\n",
      "Training Accuracy: 0.724\n",
      "KNN completed with Accuracy: 0.6405\n",
      "Training Decision Tree...\n",
      "Test Accuracy: 0.568\n",
      "Training Accuracy: 1.000\n",
      "Decision Tree completed with Accuracy: 0.5675\n",
      "Training SVM (Linear Kernel)...\n",
      "Test Accuracy: 0.706\n",
      "Training Accuracy: 0.717\n",
      "SVM (Linear Kernel) completed with Accuracy: 0.7059\n",
      "Training SVM (RBF Kernel)...\n",
      "Test Accuracy: 0.611\n",
      "Training Accuracy: 0.609\n",
      "SVM (RBF Kernel) completed with Accuracy: 0.6111\n",
      "Training Gradient Boosting...\n",
      "Test Accuracy: 0.704\n",
      "Training Accuracy: 0.980\n",
      "Gradient Boosting completed with Accuracy: 0.7037\n",
      "Training HistGradient Boosting...\n",
      "Test Accuracy: 0.727\n",
      "Training Accuracy: 1.000\n",
      "HistGradient Boosting completed with Accuracy: 0.7266\n",
      "Training AdaBoost...\n",
      "Test Accuracy: 0.547\n",
      "Training Accuracy: 0.571\n",
      "AdaBoost completed with Accuracy: 0.5468\n",
      "Training XGBoost...\n",
      "Test Accuracy: 0.725\n",
      "Training Accuracy: 1.000\n",
      "XGBoost completed with Accuracy: 0.7255\n",
      "Training LightGBM...\n",
      "[LightGBM] [Info] Total Bins 14031\n",
      "[LightGBM] [Info] Number of data points in the train set: 2142, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score -2.197225\n",
      "[LightGBM] [Info] Start training from score -2.197225\n",
      "[LightGBM] [Info] Start training from score -2.197225\n",
      "[LightGBM] [Info] Start training from score -2.197225\n",
      "[LightGBM] [Info] Start training from score -2.197225\n",
      "[LightGBM] [Info] Start training from score -2.197225\n",
      "[LightGBM] [Info] Start training from score -2.197225\n",
      "[LightGBM] [Info] Start training from score -2.197225\n",
      "[LightGBM] [Info] Start training from score -2.197225\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Test Accuracy: 0.714\n",
      "Training Accuracy: 1.000\n",
      "LightGBM completed with Accuracy: 0.7135\n",
      "Training CatBoost...\n",
      "Test Accuracy: 0.725\n",
      "Training Accuracy: 1.000\n",
      "CatBoost completed with Accuracy: 0.7255\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the models\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    # Train the model on the same training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.3f}\")\n",
    "\n",
    "    # Step 3: Calculate training accuracy \n",
    "    train_predictions = model.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    print(f\"Training Accuracy: {train_accuracy:.3f}\")\n",
    "    \n",
    "    # Calculate and store evaluation metrics\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)  # Handle zero division issue\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Save results in the dictionary\n",
    "    results_dict[name] = {\n",
    "        'Confusion Matrix': pd.DataFrame(confusion),\n",
    "        'Classification Report': pd.DataFrame(class_report).transpose(),\n",
    "        'Accuracy Score': accuracy\n",
    "    }\n",
    "    \n",
    "    print(f\"{name} completed with Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4656457e-e5e5-4c2a-88c7-e5ef855bb196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Logistic Regression: 0.7026\n",
      "Accuracy for Random Forest: 0.7070\n",
      "Accuracy for Extra Trees: 0.7102\n",
      "Accuracy for KNN: 0.6405\n",
      "Accuracy for Decision Tree: 0.5675\n",
      "Accuracy for SVM (Linear Kernel): 0.7059\n",
      "Accuracy for SVM (RBF Kernel): 0.6111\n",
      "Accuracy for Gradient Boosting: 0.7037\n",
      "Accuracy for HistGradient Boosting: 0.7266\n",
      "Accuracy for AdaBoost: 0.5468\n",
      "Accuracy for XGBoost: 0.7255\n",
      "Accuracy for LightGBM: 0.7135\n",
      "Accuracy for CatBoost: 0.7255\n"
     ]
    }
   ],
   "source": [
    "# Display or save the results as needed\n",
    "# For example, to show accuracy for each model:\n",
    "for model_name, metrics in results_dict.items():\n",
    "    print(f\"Accuracy for {model_name}: {metrics['Accuracy Score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bdf651-3b88-46bd-bccf-ce3be615f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for model evaluation with Stratified K-Fold\n",
    "cv_results = {}  # Initialize cv_results dictionary\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # Define the Stratified K-Folds\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Cross-validating {name}...\")\n",
    "    scores = cross_val_score(model, X_scaled, y, cv=kf)  # Perform cross-validation\n",
    "    cv_results[name] = f\"{scores.mean():.3f} ± {scores.std():.3f}\"\n",
    "    print(f\"Cross-validation scores for {name}: {scores.mean()} ± {scores.std()}\")\n",
    "\n",
    "# Optional: Output cross-validation results\n",
    "for model_name, score in cv_results.items():\n",
    "    print(f\"Cross-Validation Score for {model_name}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b0979-c2a2-49fb-99f4-db71abc4a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming importances dictionary is filled correctly in the previous code\n",
    "importances = {}\n",
    "top_n_features = 10  # Number of top features to save\n",
    "\n",
    "# Calculate feature importance for each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nProcessing feature importances for {name}...\")\n",
    "\n",
    "    # Skip SVM models for feature importance\n",
    "    if \"SVM\" in name:\n",
    "        print(f\"Skipping feature importance for {name} as it is not natively supported.\")\n",
    "        continue\n",
    "\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        feature_importances = model.feature_importances_\n",
    "        importances[name] = {\n",
    "            'features': X.columns,\n",
    "            'importances': feature_importances\n",
    "        }\n",
    "    elif name in ['Logistic Regression', 'KNN']:\n",
    "        perm_importance = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "        importances[name] = {\n",
    "            'features': X.columns,\n",
    "            'importances': perm_importance.importances_mean\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c228023-9acc-484f-9af1-0b0f379983bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the top features to Excel\n",
    "with pd.ExcelWriter('top_10_features_for_each_model.xlsx', engine='openpyxl') as writer:\n",
    "    for name, data in importances.items():\n",
    "        df = pd.DataFrame({\n",
    "            'Feature': data['features'],\n",
    "            'Importance': data['importances']\n",
    "        })\n",
    "        df.to_excel(writer, sheet_name=name[:30], index=False)\n",
    "\n",
    "print(\"\\nTop 10 features for each model have been saved to 'top_10_features_for_each_model.xlsx'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495c59dd-dde4-4770-a460-5d269838ce70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assuming `cv_results` and `results_dict` are defined earlier in your code\n",
    "# Save the evaluation results to Excel\n",
    "try:\n",
    "    with pd.ExcelWriter('classification_results.xlsx', engine='openpyxl') as writer:\n",
    "        # Save cross-validation results\n",
    "        cv_df = pd.DataFrame.from_dict(cv_results, orient='index', columns=['CV Score'])\n",
    "        cv_df.to_excel(writer, sheet_name='Cross_Validation')\n",
    "\n",
    "        # Save results for each model\n",
    "        for model_name, metrics in results_dict.items():\n",
    "            # Ensure the confusion matrix and classification report are DataFrames\n",
    "            confusion_matrix_df = metrics['Confusion Matrix']\n",
    "            classification_report_df = metrics['Classification Report']\n",
    "\n",
    "            # Write confusion matrix to Excel\n",
    "            confusion_matrix_df.to_excel(writer, sheet_name=f'{model_name[:28]}_Confusion', index=False)\n",
    "\n",
    "            # Write classification report to Excel\n",
    "            classification_report_df.to_excel(writer, sheet_name=f'{model_name[:28]}_Report', index=False)\n",
    "\n",
    "    print(\"Classification results have been saved to 'classification_results.xlsx'\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while saving the results: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4ce4e6-53fb-4622-b8bd-b4d7cf8696cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
